## 精选留言

![](https://raw.githubusercontent.com/yangwenmai/learning-growth/master/assets/images/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%B2%BE%E9%80%89%E7%95%99%E8%A8%80%E8%B6%8B%E5%8A%BF%E5%9B%BE.png)

|小节|留言数|
|----|----|
|开篇词 - 别让Linxu性能问题成为你的绊脚石|748|
|01 - 如何学习Linux性能优化？|292|
|CPU性能篇|13讲|
|02 - 基础篇：到底应该怎么理解“平均负载”？|492|
|03 - 基础篇：经常说的 CPU 上下文切换是什么意思？(上) |266|
|04 - 基础篇：经常说的 CPU 上下文切换是什么意思？(下) |165|
|05 - 基础篇：某个应用的CPU使用率居然达到100%，我改怎么办？|237|
|06 - 案例篇：系统CPU使用率很高，但为啥却找不到高CPU的应用？|125|
|07 - 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）|110|
|08 - 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）|97|
|09 - 基础篇：怎么理解Linux软中断？|85|
|10 - 案例篇：系统的软中断CPU使用率升高，我该怎么办？|91|
|11 - 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？|91|
|12 - 套路篇：CPU 性能优化的几个思路|56|
|13 - 答疑（一）：无法模拟出 RES 中断的问题，怎么办？|46|
|14 - 答疑（二）：如何用perf工具分析Java程序？|56|
|内存性能篇|8讲|
|15 - 基础篇：Linux内存是怎么工作的？|106|
|16 - 基础篇：怎么理解内存中的Buffer和Cache？|110|
|17 - 案例篇：如何利用系统缓存优化程序的运行效率？|94|
|18 - 案例篇：内存泄漏了，我该如何定位和处理？|92|
|19 - 案例篇：为什么系统的Swap变高了（上）|60|
|20 - 案例篇：为什么系统的Swap变高了？（下）|37|
|21 - 套路篇：如何“快准狠”找到系统内存的问题？|34|
|22 - 答疑（三）：文件系统与磁盘的区别是什么？|34|
|I/O 性能篇|10讲|
|23 - 基础篇：Linux 文件系统是怎么工作的？|59|
|24 - 基础篇：Linux 磁盘I/O是怎么工作的（上）|29|
|25 - 基础篇：Linux 磁盘I/O是怎么工作的（下）|32|
|26 - 案例篇：如何找出狂打日志的“内鬼”？|35|
|27 - 案例篇：为什么我的磁盘I/O延迟很高？|28|
|28 - 案例篇：一个SQL查询要15秒，这是怎么回事？|36|
|29 - 案例篇：Redis响应严重延迟，如何解决？|23|
|30 - 套路篇：如何迅速分析出系统I/O的瓶颈在哪里？|27|
|31 - 套路篇：磁盘 I/O 性能优化的几个思路|25|
|32 - 答疑（四）：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系|16|
|网络性能篇|13讲|
|33 - 关于 Linux 网络，你必须知道这些（上）|32|
|34 - 关于 Linux 网络，你必须知道这些（下）|41|
|35 - 基础篇：C10K 和 C1000K 回顾|42|
|36 - 套路篇：怎么评估系统的网络性能？|37|
|37 - 案例篇：DNS 解析时快时慢，我该怎么办？|25|
|38 - 案例篇：怎么使用 tcpdump 和 Wireshark 分析网络流量？|24|
|39 - 案例篇：怎么缓解 DDoS 攻击带来的性能下降问题？|31|
|40 - 案例篇：网络请求延迟变大了，我该怎么办？|26|
|41 - 案例篇：如何优化 NAT 性能？（上）|21|
|42 - 案例篇：如何优化 NAT 性能？（下）|26|
|43 - 套路篇：网络性能优化的几个思路（上）|27|
|44 - 套路篇：网络性能优化的几个思路（下）|26|
|45 - 答疑（五）：网络收发过程中，缓冲区位置在哪里？|16|
|综合实战篇|13讲|
|46 - 案例篇：为什么应用容器化后，启动慢了很多？|20|
|47 - 案例篇：服务器总是时不时丢包，我该怎么办？（上）|13|
|48 - 案例篇：服务器总是时不时丢包，我该怎么办？（下）|21|
|49 - 案例篇：内核线程 CPU 利用率太高，我该怎么办？|12|
|50 - 案例篇：动态追踪怎么用？（上）|23|
|51 - 案例篇：动态追踪怎么用？（下）|20|
|52 - 案例篇：服务吞吐量下降很厉害，怎么分析？|28|
|53 - 套路篇：系统监控的综合思路|26|
|54 - 套路篇：应用监控的一般思路|16|
|55 - 套路篇：分析性能问题的一般步骤|8|
|56 - 套路篇：优化性能问题的一般方法|10|
|57 - 套路篇：Linux 性能工具速查|10|
|58 - 答疑（六）：容器冷启动如何性能分析？|9|
|加餐篇|4讲|
|加餐（一） - 书单推荐：性能优化和Linux 系统原理|19|
|加餐（二） - 书单推荐：网络原理和 Linux 内核实现|17|
|用户故事 - “半路出家 ”，也要顺利拿下性能优化！|2|
|用户故事 - 运维和开发工程师们怎么说？|18|
|结束语 - 愿你攻克性能难关|54|
|结课测试 - 这些Linux性能知识你都掌握了吗？|3|

----

以下为各章节的精选留言中的精选摘录

### 02 - 基础篇：到底应该怎么理解“平均负载”？

**倪朋飞**

2018-11-25

1. iowait无法升高的问题，是因为案例中stress使用的是 sync() 系统调用，它的作用是刷新缓冲区内存到磁盘中。对于新安装的虚拟机，缓冲区可能比较小，无法产生大的IO压力，这样大部分就都是系统调用的消耗了。所以，你会看到只有系统CPU使用率升高。解决方法是使用stress的下一代stress-ng，它支持更丰富的选项，比如 stress-ng -i 1 --hdd 1 --timeout 600（--hdd表示读写临时文件）。
2. pidstat输出中没有%wait的问题，是因为CentOS默认的sysstat稍微有点老，源码或者RPM升级到11.5.5版本以后就可以看到了。而Ubuntu的包一般都比较新，没有这个问题。
3. mpstat无法观测的问题，案例中是等待5秒后输出1次结果就停止了，更好的做法是持续监控一段时间，比如持续观测20次：mpstat -P ALL 5 20。

**冯宇：**

2018-11-23

我一直用htop看负载，因为它更直接（在F2配置中勾选所有开关项，打开颜色区分功能），不同的负载会用不同的颜色标识。比如cpu密集型的应用，它的负载颜色是绿色偏高，iowait的操作，它的负载颜色是红色偏高等等，根据这些指标再用htop的sort就很容易定位到有问题的进程。还有个更好用的atop命令，好像是基于sar的统计生成的报告，直接就把有问题的进程标红了，更直观

**shellmode**

2018-11-23

在 sched/loadavg.c 中计算平均值的算法为EMA，这种算法的目的主要是“距离目标预测窗口越近，则数据的价值越高，对未来影响越大”如果说“更快的计算”应该只有里面的 fixed_power_int 函数用 O(log n) 的时间来算 x^n所以内核中用 EMA 来算 loadavg 本质上并不是增加计算性能，而是让 loadavg 的趋势化更明显

**孤岛**

2018-11-23

我有一点自己的理解，请老师指正。CPU比喻成一辆地铁，正在使用CPU的进程就是在地铁上的人；等待CPU的进程就是在下一站等地铁来的人；等待I/O的进程就是在下一站要上车和下车的人，虽然现在对CPU没影响，可未来会影响，所以也要考虑到平均负载上。

作者回复: 很好的比喻，补充一下这个地铁的乘客容量就是CPU个数

**DJH**

2018-11-23

老师你好，请教一个问题，现在大多数CPU有超线程能力，在计算和评估平均负载的时候，CPU的核数是指物理核数，还是超线程功能的逻辑核数？

作者回复: 逻辑核数

**杨领well**

2019-06-04

深度好文， 尤其是他分析问题的思路。Linux Load Averages: Solving the Mystery： http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html

**Way**

2018-12-16

Amazon EC2 Ubuntu 18.04 因为限制了repo源，运行apt install stress会遇到以下错误"E: Unable to locate package stress"解决方法:1) sudo nano /etc/apt/sources.list2) 添加以下三行到文件最底部, 然后保存并退出deb http://archive.ubuntu.com/ubuntu bionic main universedeb http://archive.ubuntu.com/ubuntu bionic-security main universe deb http://archive.ubuntu.com/ubuntu bionic-updates main universe3) sudo apt update4) sudo apt install stress5) 确认已安装$ stress --versionstress 1.0.4

**chenlingwx**

2018-12-07

老师您好！请教老师:最后的io密集场景二，mpstat显示sys为24％iowait为68％合计90％左右，为什么到pidstat里，stress进程却只显示35％左右的cpu？

作者回复: 进程没有iowait的概念，进程需要通过系统调用间接访问磁盘，而系统还需要通过I/O栈（后面会讲）来管理磁盘，所以有些CPU使用只能算在系统的头上

### 03-04 - 基础篇：经常说的 CPU 上下文切换是什么意思？

**小花**

2019-03-25

进程切换我想到了很多年前在银行柜台办理业务的情形。
1：银行分配各个窗口给来办理业务的人
2：如果只有1个窗口开放（系统资源不足），大部分都得等
3：如果正在办理业务的突然说自己不办了（sleep）,那他就去旁边再想想（等）
4：如果突然来了个VIP客户，可以强行插队
5：如果突然断电了（中断），都得等。。

**炀☁️**

2018-11-27

cpu上下文切换就好比一个人有好多朋友要拜访，有的朋友房子大（进程），进进出出里三层外三层，有的朋友住帐篷（线程），就拉开帐篷聊聊天，有的朋友就隔着窗户说两句话打个照面路过（中断）

**高峰**

2018-11-27

“其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。”。
CFS 调度器没有时间片的概念了，叫做虚拟运行时间。
>CFS 是 Completely Fair Scheduler 的缩写。

**行者**

2018-11-28

结合前两节，首先通过uptime查看系统负载，然后使用mpstat结合pidstat来初步判断到底是cpu计算量大还是进程争抢过大或者是io过多，接着使用vmstat分析切换次数，以及切换类型，来进一步判断到底是io过多导致问题还是进程争抢激烈导致问题。

**cuikt**

2019-04-30

可以通过以下指令进行排序，观察RES。
watch -d 'cat /proc/interrupts | sort -nr -k 2 '

### 05 - 基础篇：某个应用的CPU使用率居然达到100%，我改怎么办？

**喜哥**

2019-07-16

你好 老师通过perf查看kernel.kallsyms高达40%
如何分析呢
作者回复: 这是内核中将十六进制的符号地址转换成符号名称的模块，高是正常的，可以忽略

### 06 - 案例篇：系统CPU使用率很高，但为啥却找不到高CPU的应用？
**汤🐠🥣昱**

2019-03-14

1： 对于pidstat,vmstat,top无法定位到问题的时候。2： 可以选择perf record -g 记录。3： 用perf report查看是否可以定位到问题。4： 用pstree | grep [xx],这样定位到具体的调用方法里。5： 用grep [xx] -r [项目文件],找到具体代码位置。6： 查找源码，定位到具体位置，修改。

**Michael**

2018-12-03

如果是短时间内有大量进程在不断重启，每秒的fork调用应该很多，如果能监控到一段内都调用了哪些系统函数，同样的问题应该也能先出来吧，有这样的查看一段时间内系统函数调用情况的工具吗？

作者回复: strace可以跟踪系统调用，但没有统计功能。要跟踪的话需要使用动态追踪工具，比如bcc/BPF、systemtap 等

**付盼星**

2018-12-03

老师好，之前就遇到过一次短进程的问题导致cpu使用率过高，因为我们发布应用用的是容器，把重启策略设置为always，结果容器启动时候调用java -jar 启动应用，因为配置原因，无法启动，然后它就不停启动，现象是cpu使用率过高，好在用top能发现，毕竟进程一直在。不过还有个场景就比较难搞了，系统被入侵，不停启动进程消耗资源，你杀掉之后，它又启动新的进程，pid也不同，这种情况，有处理办法么？

作者回复: 这个问题跟今天的案例有点类似，需要找出这些进程的父进程，把父进程清理掉。我的建议是两个思路：1. 跟本文类似，用类似execsnoop的方法跟踪fork调用，定位出父进程，再把它清理掉2. 重装系统我更推荐重装系统，因为即使定位出来这些进程的根源，也不能确保其他地方就没有被感染。

### 07 - 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）

**书林**

2018-12-09

每个人的机器配置不一样，所以会出现有的机器iowait不明显，有的机器被打爆。解决办法是用docker cgroup选项对 block io做限制。假设硬盘设备为 /dev/nvme0n1，测试如下：1. 限制块设备的读写 iops 为 3: `docker run --privileged --name=app9 --device /dev/nvme0n1:/dev/nvme0n1 --device-write-iops /dev/nvme0n1:3 --device-read-iops /dev/nvme0n1:3 -itd feisky/app:iowait-new2`2. 可以查看host机器 cgroup 已为对应 docker container 添加了相关限制：```cat /sys/fs/cgroup/blkio/docker/"docker-container-id"/blkio.throttle.write_iops_device259:0 3cat /sys/fs/cgroup/blkio/docker/"docker-container-id"/blkio.throttle.read_iops_device259:0 3```3. ```docker exec -it "docker-container-id" /bin/bashroot@4cc5e6c74cc0:/# dd iflag=direct if=/dev/nvme0n1 of=/dev/null bs=1k count=10001000+0 records in1000+0 records out1024000 bytes (1.0 MB, 1000 KiB) copied, 340.004 s, 3.0 kB/s````dd` 每次从 /dev/nvme0n1 设备读取数据写到 /dev/null 设备，每次读取 1kB，一共1000次，必须为 direct 选项。可以观测到拷贝速度为 3 kB/s，即 1kB * 3，说明cgroup 限制 `blkio.throttle.read_iops_device` 生效。4. 观察host机器 iowait 已经上去。```top - 12:10:22 up 1:25, 1 user, load average: 0.88, 0.81, 0.83任务: 780 total, 1 running, 227 sleeping, 0 stopped, 552 zombie%Cpu0 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 s%Cpu1 : 2.7 us, 0.0 sy, 0.0 ni, 97.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 s%Cpu2 : 0.0 us, 0.0 sy, 0.0 ni, 0.0 id,100.0 wa, 0.0 hi, 0.0 si, 0.0 s%Cpu3 : 5.3 us, 7.9 sy, 0.0 ni, 84.2 id, 0.0 wa, 0.0 hi, 2.6 si, 0.0 sMiB Mem : 7863.3 total, 230.4 free, 3847.2 used, 3785.8 buff/cacheMiB Swap: 8192.0 total, 8191.5 free, 0.5 used. 3191.1 avail Mem ```zombie数那么高是因为这个 docker container 已经运行20多分钟了。供大家参考:)

作者回复: 谢谢分享，见到Docker高手了😊。 这样的确可以达到IO限制的目的，不过使用系统级工具分析的时候，会有很大不同，比如iostat看看磁盘使用率可能还是很空闲；或者看看内核调用栈也有些不同。不过这倒是不错的性能隔离方案👍

**徐洲更**

2018-12-27

关于不可中断的IO负荷导致服务器性能提高，这两天刚好有了一个实战机会https://www.jianshu.com/p/d7edbff7dda6

作者回复: 👍 总结的很棒

### 08 - 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）

**mj4ever**

2018-12-07

通过本篇知识实践，谈谈学习感受：1、在使用perf进一步排查代码时，由于对I/O深层次知识不了解，所以，无法进行分析2、看到有人留言“直接读写磁盘为什么对数据库程序更友好” 以及 文章中提到“new_sync_read” & “blkdev_direct_IO”，就去百度了下，找到了这篇文章《Linux 中直接 I/O 机制的介绍》，https://www.ibm.com/developerworks/cn/linux/l-cn-directio/3、文章中讲解了 缓存I/O、自缓存应用程序、直接I/O技术、异步访问文件方式等知识，能看懂一些，还谈不上深入理解，但是可以回答上面的一些问题：（1）通常情况下，缓存I/O会提高性能，但是对于数据库类型的软件，它会比操作系统更了解数据库中存放的数据，可以提供一种更有效的机制（如自缓存应用程序）来提高数据库中数据的存取性能（2）要在块设备中执行直接 I/O，进程必须在打开文件的时候设置对文件的访问模式为 O_DIRECT

**Adam**

2018-12-07

数据库服务器，一般为了充分提高性能，可能会考虑绕过内核缓冲区，由自己在用户态空间实现并管理IO缓冲区，包括缓存机制等。即在open系统调用中增加参数选项O_DIRECT，用它打开的文件便可以绕过内核缓冲区直接访问。

### 09 - 基础篇：怎么理解Linux软中断？

**我来也**

2018-12-10

[D9打卡]======================================问题:怎么理解软中断?我的理解比较简单粗暴, 硬中断是硬件产生的,比如键盘、鼠标的输入，硬盘的写入读取、网卡有数据了；软中断是软件产生的，比如程序内的定时器、[文中提到的RCU锁]。再加上今天的上半部下半部，更好的理解了网卡的处理实际是有硬中断和软中断的。======================================问题:有没有碰到过因为软中断出现的性能问题?有，且是血淋淋的教训。之前的c程序用到了别人写的动态库[如:lib.a]，在物理机上，进程的cpu利用率在0%；而切换到了云服务器，即使空载，单进程的cpu利用率都有30%+。以前没经验嘛,各种自查,无结果,但是自己的进程cpu利用率又那么高,总是不安心.后来才通过vmstat 检测到系统的软中断每秒有100W+次.最后各自百度,找人,才发现是那个动态库在处理网络收发消息时,使用了usleep(1)来休息,每次休息1纳秒,单次中断的耗时都不止1纳秒.--------------------------------------如果是现在,我会如下分析:1.检测是哪个线程占用了cpu: top -H -p XX 1 / pidstat -wut -p XX 1 2.在进程中打印各线程号. 找到是哪个线程.[ 此过程也可以省略 但可以快速定位线程]3.第一步应该可以判断出来中断数过高. 再使用 cat /proc/softirqs 查看是哪种类型的中断数过高.4.不知道perf report -g -p XX 是否可以定位到具体的系统调用函数.5.最终还是要查看源码,定位具体的位置,并加以验证.--------------------------------------感觉现在随便怎么分析都可以快速定位到是动态库的锅.想当初可是好几个月都无能为力啊, 最后还是几个人各种查,搞了一周多才定位到原因.最后再吐槽下,没有root权限的普通账户真是不方便啊,有些工具只能安装在自己的目录下, 还有些好用的工具根本无权限运行,哎...

作者回复: 嗯嗯，已经是很有经验的老手了😊

大多数情况下 root 权限都是必须的，还是准备个root权限的环境实践吧

**Linuxer**

2018-12-10

经常听同事说大量的网络小包会导致性能问题，一直不太理解，从今天的课程来看，是不是大量的小网络包会导致频繁的硬中断和软中断呢？希望老师给予指点，谢谢

作者回复: 正解

**沙皮狗**

2019-03-08

老师，有一点很疑惑。在《Linux内核设计与实现》一书中提到"在2.6以后的内核中提到，目前有三种方式实现中断下半部：工作队列，tasklet和软中断，软中断机制并不完全等同于中断下半部，很多人把所有下半部当成是软中断。"请问这部分怎么理解？麻烦老师解答一下

作者回复: 这儿区分的更细了，tasklet 也是基于软中断的，而工作队列则是用于可以睡眠的下半部处理过程

### 10 - 案例篇：系统的软中断CPU使用率升高，我该怎么办？

**倪朋飞 置顶**

2018-12-12

统一回复一下终端卡顿的问题，这个是由于网络延迟增大（甚至是丢包）导致的。比如你可以再拿另外一台机器（也就是第三台）在 hping3 运行的前后 ping 一下案例机器，ping -c3 <ip>hping3 运行前，你可能看到最长的也不超过 1 ms：3 packets transmitted, 3 received, 0% packet loss, time 2028msrtt min/avg/max/mdev = 0.815/0.914/0.989/0.081 ms而 hping3 运行时，不仅平均延迟增长到了 245 ms，而且还会有丢包的发生：3 packets transmitted, 2 received, 33% packet loss, time 2026msrtt min/avg/max/mdev = 240.637/245.758/250.880/5.145 ms网络问题的排查方法在后面的文章中还会讲，这儿只是从 CPU 利用率的角度出发，你可以发现也有可能是网络导致的问题。

**Joe**

2019-04-06

从网络统计中看到很大的流量，有没有办法知道流量到底是访问哪个端口呢？

作者回复: 可以用iptraf或者iftop查看

### 14 - 答疑（二）：如何用perf工具分析Java程序？

**我来也**

2018-12-21

[D14打卡]很赞同老师的观点:"任何东西的第一遍学习有不懂的地方很正常，忍住恐惧别放弃，继续往后走，前面很多问题可能会一并解决掉 ，再看第二遍、第三遍就更轻松了。"我好像很早就这样实践了: 第一遍不管看不看得懂,先尽量细看. 再特意过一段时间回头重新学一遍,除了能掌握更多的东西,还能体会到"温故而知新"的感觉.----------------------------现在就是"师傅领进门,修行看个人.""先从最基本的原理开始，掌握性能分析的思路，然后再逐步深入，探究细节"----------------------------自从学了专栏,越来越觉得自己的<英语>该好好补补了,深感能力不足啊.那么多好的资源,一手资料几乎都是英文的,看不懂真是可惜了!

作者回复: 英语也是基本要求，多读多看就熟悉了😊

**辣椒**

2019-01-07

老师，我把perf.data拷贝进容器，然后在容器中按照提示安装了perf, 再执行perf_4.9 report时报以下信息：Kernel address maps (/proc/{kallsyms,modules}) were restricted. Check /proc/sys/kernel/kptr_restrict before running 'perf record'As no suitable kallsyms nor vmlinux was found, kernel samples can't be resolved. Samples in kernel modules can't be resolved as well.  xPress any key... 我本身的机器是centos7.2. 请老师提示一下解决的思路，谢谢！ 

作者回复: echo 0> /proc/sys/kernel/kptr_restrict

**子轩Zixuan**

2018-12-23

趁周末跟上了老师的脚步，老师讲解的很好，感谢！另外我注意到老师在专栏里的实例都是现场调试，但是我遇到过实际情况需要尽快恢复服务，先把代码还原重新发布保证服务可用，只留下一台保留问题现场的机器，但是已经不接受请求了，像这种情况除了事先监控以外，还有别的方案能定位问题吗？

作者回复: 是的，线上问题要优先恢复，排查不能花过多时间，所以很多情况下都要靠监控系统了解当时的状况。除此之外，原来服务还在的话，可以试试能否重现问题，比如模拟当时的请求；或者也可以从日志中寻找线索。

### 15 - 基础篇：Linux内存是怎么工作的？

**JohnT3e**

2018-12-24

目前我配合使用《Operating System Concepts》这本书学习此专栏，也是一个不错的选择。此书中的第四部分“Memory Management”对今天这部分内容有较为详细的描述，感兴趣的同学可以去看一下。另外对于TOP命令中输出的内存情况解释，可以认真看一下man手册的内容。如果你动手能力比较强，可以看https://blog.holbertonschool.com/hack-the-virtual-memory-malloc-the-heap-the-program-break/这篇博客，手把手教你使用程序（C语言）来实际地去搞清楚虚拟内存分布。

作者回复: 👍 谢谢分享，这篇博客很详细

**梦回汉唐**

2019-03-27

1、调用c标准库的都是用户空间的调用，用户空间的内存分配都是基于buddy算法（伙伴算法），并不涉及slab2、brk()方式之所以会产生内存碎片，是由于brk分配的内存是推_edata指针，从堆的低地址向高地址推进。这种情况下，如果高地址的内存不释放，低地址的内存是得不到释放的3、mmap()方式分配的内存，是在堆与栈之间的空闲区域分配虚拟内存，直接拿到的是内存地址，可以直接操作内存的释放上述的都是在用户空间发生的行为，只有在内核空间，内核调用kmalloc去分配内存的时候，才会涉及到slab

**我来也**

2018-12-24

[D15打卡]linux的内存跟windows的很不一样。类linux的系统会尽量使用内存缓存东西，提供运行效率。所以linux/mac显示的free剩余内存通常很小，但实际上被缓存的cache可能很大，并不代表系统内存紧张！曾经就闹过笑话，看见系统free值很低，怕程序因为oom被系统杀掉，还特意写个c程序去挤内存。程序不停的申请1MB内存然后memset，随机挑几个位置写，保证申请的都被加载到物理内存中。（跟文中描述的一致，只申请不使用不会加载到物理内存）然后挤的差不多了就把测试程序关掉。看上去free变大了很多很开心。现在想想，就是掩耳盗铃罢了。以前物理机上还有swap交换分区，现在都是云服务器，基本没有了该分区。也不会遇到因为频繁使用交换分区导致性能下降的问题了。我内存方面的问题遇到的都比较简单，基本上就是top/free看看系统和各程序的，找到有问题的程序，看看是否有内存泄露。平常不泄漏都是够用的。redis对内存比较敏感，曾经就因为配置项是默认值，在内存用完后，所有的set操作都直接返回错误，导致线上系统故障。（redis在备份时会新开一个进程，实际使用内存量会翻番。）后来会定期检查redis 的info memory 看内存使用情况。——————————期待的内存篇开始了，好开心！又可以跟着老师学新知识啦！

作者回复: 👍 谢谢分享你的经历。缓存和swap后面都还会细讲

**赵强强**

2018-12-24

倪老师，“Operating Systems Design and Implementation”里面说，大部分页式存储管理，页表是存储到内存里面的，为降低频繁访问内存计算物理地址，引入TLB用于缓存常用映射以提升性能。以现在流行的linux为例，本节课说页表存储在MMU是否还正确呢？

作者回复: MMU全称就是内存管理单元，管理地址映射关系（也就是页表）。但MMU的性能跟CPU比还是不够快，所以又有了TLB。TLB实际上是MMU的一部分，把页表缓存起来以提升性能。

**二进制之路**

2020-02-27

写了篇文章，部分内容参考了本篇：《计算机虚拟存储器的一点琐碎记录》为了更加有效地管理存储器并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟存储器（VM）。https://mp.weixin.qq.com/s/mo8cr14ddyZJA0EvyxC6lw

**柏森森**

2019-10-21

请教下buffer和cache的区别？有以下几个疑问：1）都是内存吗？2）是因为作用不同，划分的不同大小的区域吗？3）/tmp目录默认是在内存中吗？

作者回复: 1）都是内存2）是的3）一般是根目录挂载的磁盘

**afterdream**

2019-08-08

【课后题】内存=虚拟内存+物理内存，对于应用程序+驱动程序，我们直接操作的都是虚拟内存，虚拟内存通过MMU的页表映射到物理内存。【遇到的问题】之前在调试网卡驱动的时候，遇到一个问题，网卡刚开始正常运行，但是每次大概7h，系统就崩掉了。后来通过内核log，并通过free工具，发现内存越来越少，最终定位是内存泄漏问题，于是在一个合适的地方，释放了申请的内存。【解决了之前的认知】之前只知道交换分区是在内存不足的是否，使用硬盘的一块充当内存。如今明白这是内存回收的范畴。

**格非**

2019-07-19

倪老师，在《深入理解计算机系统》第三版 Chapter9 虚拟内存章节，提到“CPU芯片上叫做内存管理单元（Memory Management Unit, MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理”，"同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在DRAM中的某个地方；这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做页表（page table)的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与DRAM之间来回传送页“，这里说的页表是存放在内存中，是不是书中的知识点过时了？

作者回复: 没有过时。因为现在系统的页表都很大，只靠寄存器是存不下的，所以只会通过TLB缓存一小部分页表的索引，大部分页表内容还是放在内存中。

**东宇**

2019-03-26

老师 问下 想详细了解下jemalloc工作原理 有什么好的讲解吗 感觉一直停留在表面 多谢！

作者回复: 最好的方法去看文档和源码

**blackpiglet**

2019-02-02

请问老师，用 free 命令查看系统内存，标记为 free 内存大于 available 的内存是什么原因呢？正常来讲，不应该是反过来吗？这个物理机是用来跑 k8s 的，关闭了 swap，这有影响吗？$ free total used free shared buff/cache availableMem: 131932792 27384328 11655508 1454684 92892956 100732052Swap: 0 0 0k8s@ubuntu54:~$

作者回复: 这是看错了吧，free 11G < available 100G数字比较大的时候，建议用 free -g

**Geek_41dcba**

2019-01-17

刚在将内存性能几篇做一个总体的整理，在整理到对于内存页表管理感觉很像是它像是一个B+树的演变，空间占用小（如果是4级，每级表的大小是10就可以表示到一百多万），并且查询效率在O(logN)，log的底是页表的级数。如果页是大页分配时有一个说法是TLB中的命中率就提高，也就提高访问速度。那页的大小设置怎样设置才适合我们自己的应用场景，性能上除了TLB命中率以为还有那些影响了？同时在内存使用时才映射到物理内存页上，文中提到的缺页异常是不是一个中断？（我看了一遍/proc下的两个中断文件内容感觉没一个有关系）

作者回复: 除了TLB，内存的动态分配和回收、缓存、Swap等都会影响性能。异常跟中断不一样，但可以类比理解

**13001236383**

2018-12-27

老师请教两个问题第1.每个用户进程在运行时都会在用户空间的各段空间内申请自己的空间，比如说每个进程都会在栈空间申请自己的栈，在堆空间申请自己的堆空间？各进程是怎么实现访问隔离的？2.用户态内存和内核态内存是不是只从用户进程角度来看？内核使用内存是直接分配了，还是也是需要进行映射？多谢老师。

作者回复: 1. 内核保证内存的隔离2. 内核中大部分是直接分配物理页，但是也可以通过vmalloc来分配不连续的物理内存，这时候必须通过页表才能知道映射关系

**VIC**

2018-12-26

nmap为什么会缺页异常?

作者回复: 这应该是说mmap吧，缺页异常是内存分配必要步骤：陷入内核态分配内存并完成内存映射的过程

**Vicky🐣🐣🐣**

2018-12-25

老师，文中说一个进程运行占用的CPU越多，oom_score就越小这里不应该是 一个进程消耗的内存越少，oom_score就越小吗？麻烦老师解答一下

作者回复: 是的，内存跟oom score正相关，但是CPU用多了会减分的，也就是说CPU用的越多也就不容易因OOM杀死

