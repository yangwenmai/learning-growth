## 23 | 基础篇：Linux 文件系统是怎么工作的？

### 笔记

文件系统，是对存储设备上的文件，进行组织管理的机制。

Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。

- 索引节点 inode，用来记录文件的元数据。包括 inode 编号、文件大小、访问权限、修改日期、数据的位置。
索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中，索引节点(inode)同样占用磁盘空间。
- 目录项 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。
是有内核维护的一个内存数据结构，也被称为目录项缓存。

磁盘读写的最小单位是扇区，然而扇区只有 512B 大小，如果每次都读写这么小的单位，效率一定很低。所以，文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。

![](https://static001.geekbang.org/resource/image/32/47/328d942a38230a973f11bae67307be47.png)

注意事项：
1. 目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。
2. 磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。

![](https://static001.geekbang.org/resource/image/72/12/728b7b39252a1e23a7a223cdf4aa1612.png)


文件读写方式的各种差异，导致 I/O 的分类多种多样。最常见的有，缓冲与非缓冲 I/O、直接与非直接 I/O、阻塞与非阻塞 I/O、同步与异步 I/O 等。

经常使用 slabtop ，来找到占用内存最多的缓存类型。

### 命令

```sh
$ df /dev/sda1 
Filesystem     1K-blocks    Used Available Use% Mounted on 
/dev/sda1       30308240 3167020  27124836  11% / 

# -h 以获得更好的可读性显示
$ df -h /dev/sda1 
Filesystem      Size  Used Avail Use% Mounted on 
/dev/sda1        29G  3.1G   26G  11% / 

# -i 可以查看 inode
$ df -i /dev/sda1 
Filesystem      Inodes  IUsed   IFree IUse% Mounted on 
/dev/sda1      3870720 157460 3713260    5% / 
```

```sh
# 从 /proc/meminfo 中获得他们的大小
$ cat /proc/meminfo | grep -E "SReclaimable|Cached" 
Cached:           748316 kB 
SwapCached:            0 kB 
SReclaimable:     179508 kB 
```

```sh
# 所有目录项和各种文件系统索引节点的缓存情况:
$ cat /proc/slabinfo | grep -E '^#|dentry|inode' 
# name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <limit> <batchcount> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail> 
xfs_inode              0      0    960   17    4 : tunables    0    0    0 : slabdata      0      0      0 
... 
ext4_inode_cache   32104  34590   1088   15    4 : tunables    0    0    0 : slabdata   2306   2306      0hugetlbfs_inode_cache     13     13    624   13    2 : tunables    0    0    0 : slabdata      1      1      0 
sock_inode_cache    1190   1242    704   23    4 : tunables    0    0    0 : slabdata     54     54      0 
shmem_inode_cache   1622   2139    712   23    4 : tunables    0    0    0 : slabdata     93     93      0 
proc_inode_cache    3560   4080    680   12    2 : tunables    0    0    0 : slabdata    340    340      0 
inode_cache        25172  25818    608   13    2 : tunables    0    0    0 : slabdata   1986   1986      0 
dentry             76050 121296    192   21    1 : tunables    0    0    0 : slabdata   5776   5776      0 
```


```sh
# 按下c按照缓存大小排序，按下a按照活跃对象数排序 
$ slabtop 
Active / Total Objects (% used)    : 277970 / 358914 (77.4%) 
Active / Total Slabs (% used)      : 12414 / 12414 (100.0%) 
Active / Total Caches (% used)     : 83 / 135 (61.5%) 
Active / Total Size (% used)       : 57816.88K / 73307.70K (78.9%) 
Minimum / Average / Maximum Object : 0.01K / 0.20K / 22.88K 

  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME 
69804  23094   0%    0.19K   3324       21     13296K dentry 
16380  15854   0%    0.59K   1260       13     10080K inode_cache 
58260  55397   0%    0.13K   1942       30      7768K kernfs_node_cache 
   485    413   0%    5.69K     97        5      3104K task_struct 
  1472   1397   0%    2.00K     92       16      2944K kmalloc-2048 
```

### 发现面试题


### 专栏金句

在 Linux 中一切皆文件。
>不仅普通的文件和目录，就连块设备、套接字、管道等，也都要通过统一的文件系统来管理。


### 课后题

`find / -name file-name` 这个命令，会不会导致系统的缓存升高呢？如果有影响，又会导致哪种类型的缓存升高呢？

这个命令，会不会导致系统的缓存升高呢？
--> 会的
如果有影响，又会导致哪种类型的缓存升高呢？
--> /xfs_inode/ proc_inode_cache/dentry/inode_cache

实验步骤：
1. 清空缓存：echo 3 > /proc/sys/vm/drop_caches ; sync
2. 执行find ： find / -name test
3. 发现更新top 4 项是：
  OBJS ACTIVE USE OBJ SIZE SLABS OBJ/SLAB CACHE SIZE NAME
 37400 37400 100% 0.94K 2200 17 35200K xfs_inode
 36588 36113 98% 0.64K 3049 12 24392K proc_inode_cache
104979 104979 100% 0.19K 4999 21 19996K dentry
 18057 18057 100% 0.58K 1389 13 11112K inode_cache

find / -name 这个命令是全盘扫描（既包括内存文件系统又包含本地的xfs【我的环境没有mount 网络文件系统】），所以 inode cache & dentry & proc inode cache 会升高。

另外，执行过了一次后再次执行find 就机会没有变化了，执行速度也快了很多，也就是下次的find大部分是依赖cache的结果。